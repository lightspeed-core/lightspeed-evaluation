# LightSpeed Evaluation Framework - Sample/Mock Data

- conversation_group_id: "conv_group_1"
  description: "conversation group description"

  turn_metrics:
    - "ragas:faithfulness"
    - "ragas:response_relevancy"
    - "ragas:context_precision_without_reference"

  turn_metrics_metadata:
    "ragas:faithfulness":
      threshold: 0.99
  conversation_metrics: []
  conversation_metrics_metadata: {}

  turns:
    - turn_id: "1"
      query: "User query"
      response: "API response"
      contexts:
        - "Context 1"
        - "Context 2"
      expected_response: "Expected Response"

- conversation_group_id: "conv_group_2"
  description: "conversation group description"

  turn_metrics:
    - "ragas:context_recall"
    - "ragas:context_relevance"
    - "ragas:context_precision_with_reference"

  turn_metrics_metadata: {}
  conversation_metrics: []
  conversation_metrics_metadata: {}

  turns:
    - turn_id: "1"
      query: "User Query"
      response: "API Response"
      contexts:
        - "Context 1"
      expected_response: "Expected Response"

- conversation_group_id: "conv_group_3"
  description: "conversation group description"

  turn_metrics:
    - "custom:answer_correctness"

  turn_metrics_metadata: {}

  conversation_metrics:
    - "deepeval:conversation_completeness"
    - "deepeval:conversation_relevancy"

  conversation_metrics_metadata: {}

  turns:
    - turn_id: "1"
      query: "User Query 1"
      response: "API Response 1"
      contexts:
        - "Context"
      expected_response: "Expected Response 1"

    - turn_id: "2"
      query: "User Query 2"
      response: "API Response 2"
      contexts:
        - "Context"
      expected_response: "Expected Response 2"
